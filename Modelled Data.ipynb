{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb2f52b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "#from xclim import sdba\n",
    "#from xclim.core.calendar import convert_calendar\n",
    "#import xclim.indices as xci\n",
    "#import xclim.ensembles as xce\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import gcsfs\n",
    "import zarr\n",
    "import os\n",
    "\n",
    "\n",
    "# lat and lon coordinates for Edmonton\n",
    "#lat_edm = \n",
    "#lon_edm = \n",
    "\n",
    "# time periods for historical and future periods\n",
    "years_hist = range(1980, 2011) # remember that range(start, end) is not inclusive of `end`\n",
    "years_future = range(2030, 2061)\n",
    "\n",
    "# url for the CSV file that contains the data catalog\n",
    "url_gcsfs_catalog = 'https://storage.googleapis.com/cmip6/cmip6-zarr-consolidated-stores.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a225bd65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lon: 60, lat: 120)\n",
      "Coordinates:\n",
      "  * lon      (lon) float64 32.02 32.06 32.1 32.15 ... 34.35 34.4 34.44 34.48\n",
      "  * lat      (lat) float64 15.98 15.94 15.9 15.85 ... 11.15 11.1 11.06 11.02\n",
      "Data variables:\n",
      "    *empty*\n"
     ]
    }
   ],
   "source": [
    "# Open the NetCDF file\n",
    "file_path = 'G:/Other computers/My MacBook Air/Documents/School/MEnvSc/UTCDW Hackathon/TerraClimate.tmax.monthlymean.1980-2010.nc'  \n",
    "nc_data = xr.open_dataset(file_path)\n",
    "\n",
    "# Extract longitude and latitude values\n",
    "stn_lon = nc_data.lon.values\n",
    "stn_lat = nc_data.lat.values\n",
    "\n",
    "# Create an xarray Dataset with lon and lat as coordinates\n",
    "coords = {'lon': stn_lon, 'lat': stn_lat}\n",
    "coords_ds = xr.Dataset(coords=coords)\n",
    "\n",
    "# Convert the calendar if needed (optional)\n",
    "#coords_ds_noleap = convert_calendar(coords_ds, 'noleap')\n",
    "\n",
    "# Access the extracted variables if needed (optional)\n",
    "#tas_obs_noleap = coords_ds_noleap.tas\n",
    "\n",
    "# Display the coordinates dataset\n",
    "print(coords_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07d9b7d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\IPython\\core\\formatters.py\", line 223, in catch_format_error\n",
      "    r = method(self, *args, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\IPython\\core\\formatters.py\", line 344, in __call__\n",
      "    return method()\n",
      "           ^^^^^^^^\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py\", line 1175, in _repr_html_\n",
      "    else:\n",
      "          \n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\format.py\", line 1074, in to_html\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\html.py\", line 88, in to_string\n",
      "    lines = self.render()\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\html.py\", line 644, in render\n",
      "    super().render()\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\html.py\", line 94, in render\n",
      "    self._write_table()\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\html.py\", line 267, in _write_table\n",
      "    self._write_header(indent + self.indent_delta)\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\html.py\", line 403, in _write_header\n",
      "    self._write_col_header(indent + self.indent_delta)\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\html.py\", line 383, in _write_col_header\n",
      "    row.extend(self._get_columns_formatted_values())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\html.py\", line 611, in _get_columns_formatted_values\n",
      "    return self.columns._format_flat(include_name=False)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Index' object has no attribute '_format_flat'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\executing\\executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "        activity_id institution_id      source_id experiment_id member_id  \\\n",
       "378916  ScenarioMIP   CSIRO-ARCCSS     ACCESS-CM2        ssp245  r1i1p1f1   \n",
       "378917  ScenarioMIP   CSIRO-ARCCSS     ACCESS-CM2        ssp245  r1i1p1f1   \n",
       "379701  ScenarioMIP   CSIRO-ARCCSS     ACCESS-CM2        ssp245  r1i1p1f1   \n",
       "379704  ScenarioMIP   CSIRO-ARCCSS     ACCESS-CM2        ssp245  r1i1p1f1   \n",
       "203687  ScenarioMIP            AWI  AWI-CM-1-1-MR        ssp245  r1i1p1f1   \n",
       "...             ...            ...            ...           ...       ...   \n",
       "380485  ScenarioMIP            NCC     NorESM2-MM        ssp245  r1i1p1f1   \n",
       "380505  ScenarioMIP            NCC     NorESM2-MM        ssp245  r1i1p1f1   \n",
       "515029  ScenarioMIP        AS-RCEC        TaiESM1        ssp245  r1i1p1f1   \n",
       "515020  ScenarioMIP        AS-RCEC        TaiESM1        ssp245  r1i1p1f1   \n",
       "515032  ScenarioMIP        AS-RCEC        TaiESM1        ssp245  r1i1p1f1   \n",
       "\n",
       "       table_id variable_id grid_label  \\\n",
       "378916      day      tasmin         gn   \n",
       "378917      day      tasmax         gn   \n",
       "379701      day          pr         gn   \n",
       "379704      day         hur         gn   \n",
       "203687      day      tasmin         gn   \n",
       "...         ...         ...        ...   \n",
       "380485      day         hur         gn   \n",
       "380505      day      tasmax         gn   \n",
       "515029      day      tasmax         gn   \n",
       "515020      day          pr         gn   \n",
       "515032      day      tasmin         gn   \n",
       "\n",
       "                                                   zstore  dcpp_init_year  \\\n",
       "378916  gs://cmip6/CMIP6/ScenarioMIP/CSIRO-ARCCSS/ACCE...             NaN   \n",
       "378917  gs://cmip6/CMIP6/ScenarioMIP/CSIRO-ARCCSS/ACCE...             NaN   \n",
       "379701  gs://cmip6/CMIP6/ScenarioMIP/CSIRO-ARCCSS/ACCE...             NaN   \n",
       "379704  gs://cmip6/CMIP6/ScenarioMIP/CSIRO-ARCCSS/ACCE...             NaN   \n",
       "203687  gs://cmip6/CMIP6/ScenarioMIP/AWI/AWI-CM-1-1-MR...             NaN   \n",
       "...                                                   ...             ...   \n",
       "380485  gs://cmip6/CMIP6/ScenarioMIP/NCC/NorESM2-MM/ss...             NaN   \n",
       "380505  gs://cmip6/CMIP6/ScenarioMIP/NCC/NorESM2-MM/ss...             NaN   \n",
       "515029  gs://cmip6/CMIP6/ScenarioMIP/AS-RCEC/TaiESM1/s...             NaN   \n",
       "515020  gs://cmip6/CMIP6/ScenarioMIP/AS-RCEC/TaiESM1/s...             NaN   \n",
       "515032  gs://cmip6/CMIP6/ScenarioMIP/AS-RCEC/TaiESM1/s...             NaN   \n",
       "\n",
       "         version  \n",
       "378916  20191108  \n",
       "378917  20191108  \n",
       "379701  20191108  \n",
       "379704  20191108  \n",
       "203687  20190529  \n",
       "...          ...  \n",
       "380485  20191108  \n",
       "380505  20191108  \n",
       "515029  20210222  \n",
       "515020  20210222  \n",
       "515032  20210222  \n",
       "\n",
       "[100 rows x 11 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open the Google Cloud model data catalog with pandas\n",
    "df_catalog = pd.read_csv(url_gcsfs_catalog)\n",
    "\n",
    "# search for models which have daily tas data from the historical and SSP3-3.0 scenarios\n",
    "search_string_mm = (\n",
    "    \"(table_id == 'day') & \"\n",
    "    \"(variable_id in ['tasmax', 'tasmin', 'pr', 'hur']) & \"\n",
    "    \"(member_id == 'r1i1p1f1') & \"\n",
    "    \"(experiment_id in ['ssp245'])\"\n",
    ")\n",
    "df_search_mm = df_catalog.query(search_string_mm).sort_values('source_id')\n",
    "df_search_mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75c5c9d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\IPython\\core\\formatters.py\", line 223, in catch_format_error\n",
      "    r = method(self, *args, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\IPython\\core\\formatters.py\", line 344, in __call__\n",
      "    return method()\n",
      "           ^^^^^^^^\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py\", line 1175, in _repr_html_\n",
      "    else:\n",
      "          \n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\format.py\", line 1074, in to_html\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\html.py\", line 88, in to_string\n",
      "    lines = self.render()\n",
      "            ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\html.py\", line 644, in render\n",
      "    super().render()\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\html.py\", line 94, in render\n",
      "    self._write_table()\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\html.py\", line 267, in _write_table\n",
      "    self._write_header(indent + self.indent_delta)\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\html.py\", line 403, in _write_header\n",
      "    self._write_col_header(indent + self.indent_delta)\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\html.py\", line 383, in _write_col_header\n",
      "    row.extend(self._get_columns_formatted_values())\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\html.py\", line 611, in _get_columns_formatted_values\n",
      "    return self.columns._format_flat(include_name=False)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Index' object has no attribute '_format_flat'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\stack_data\\core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"C:\\Users\\indra\\anaconda3\\Lib\\site-packages\\executing\\executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "        activity_id       institution_id      source_id experiment_id  \\\n",
       "203687  ScenarioMIP                  AWI  AWI-CM-1-1-MR        ssp245   \n",
       "203680  ScenarioMIP                  AWI  AWI-CM-1-1-MR        ssp245   \n",
       "203625  ScenarioMIP                  AWI  AWI-CM-1-1-MR        ssp245   \n",
       "203618  ScenarioMIP                  AWI  AWI-CM-1-1-MR        ssp245   \n",
       "110222  ScenarioMIP                CCCma        CanESM5        ssp245   \n",
       "110210  ScenarioMIP                CCCma        CanESM5        ssp245   \n",
       "110221  ScenarioMIP                CCCma        CanESM5        ssp245   \n",
       "110311  ScenarioMIP                CCCma        CanESM5        ssp245   \n",
       "425694  ScenarioMIP  EC-Earth-Consortium      EC-Earth3        ssp245   \n",
       "425877  ScenarioMIP  EC-Earth-Consortium      EC-Earth3        ssp245   \n",
       "425687  ScenarioMIP  EC-Earth-Consortium      EC-Earth3        ssp245   \n",
       "255053  ScenarioMIP                  CAS      FGOALS-g3        ssp245   \n",
       "255060  ScenarioMIP                  CAS      FGOALS-g3        ssp245   \n",
       "255056  ScenarioMIP                  CAS      FGOALS-g3        ssp245   \n",
       "209150  ScenarioMIP                  INM      INM-CM5-0        ssp245   \n",
       "209158  ScenarioMIP                  INM      INM-CM5-0        ssp245   \n",
       "209169  ScenarioMIP                  INM      INM-CM5-0        ssp245   \n",
       "209180  ScenarioMIP                  INM      INM-CM5-0        ssp245   \n",
       "48510   ScenarioMIP                 IPSL   IPSL-CM6A-LR        ssp245   \n",
       "48355   ScenarioMIP                 IPSL   IPSL-CM6A-LR        ssp245   \n",
       "48506   ScenarioMIP                 IPSL   IPSL-CM6A-LR        ssp245   \n",
       "206821  ScenarioMIP                 IPSL   IPSL-CM6A-LR        ssp245   \n",
       "219098  ScenarioMIP                MPI-M  MPI-ESM1-2-LR        ssp245   \n",
       "219099  ScenarioMIP                MPI-M  MPI-ESM1-2-LR        ssp245   \n",
       "219130  ScenarioMIP                MPI-M  MPI-ESM1-2-LR        ssp245   \n",
       "219088  ScenarioMIP                MPI-M  MPI-ESM1-2-LR        ssp245   \n",
       "204547  ScenarioMIP                  MRI     MRI-ESM2-0        ssp245   \n",
       "204583  ScenarioMIP                  MRI     MRI-ESM2-0        ssp245   \n",
       "204972  ScenarioMIP                  MRI     MRI-ESM2-0        ssp245   \n",
       "204548  ScenarioMIP                  MRI     MRI-ESM2-0        ssp245   \n",
       "\n",
       "       member_id table_id variable_id grid_label  \\\n",
       "203687  r1i1p1f1      day      tasmin         gn   \n",
       "203680  r1i1p1f1      day      tasmax         gn   \n",
       "203625  r1i1p1f1      day         hur         gn   \n",
       "203618  r1i1p1f1      day          pr         gn   \n",
       "110222  r1i1p1f1      day      tasmin         gn   \n",
       "110210  r1i1p1f1      day         hur         gn   \n",
       "110221  r1i1p1f1      day      tasmax         gn   \n",
       "110311  r1i1p1f1      day          pr         gn   \n",
       "425694  r1i1p1f1      day          pr         gr   \n",
       "425877  r1i1p1f1      day      tasmin         gr   \n",
       "425687  r1i1p1f1      day      tasmax         gr   \n",
       "255053  r1i1p1f1      day      tasmin         gn   \n",
       "255060  r1i1p1f1      day      tasmax         gn   \n",
       "255056  r1i1p1f1      day          pr         gn   \n",
       "209150  r1i1p1f1      day         hur        gr1   \n",
       "209158  r1i1p1f1      day          pr        gr1   \n",
       "209169  r1i1p1f1      day      tasmax        gr1   \n",
       "209180  r1i1p1f1      day      tasmin        gr1   \n",
       "48510   r1i1p1f1      day         hur         gr   \n",
       "48355   r1i1p1f1      day      tasmin         gr   \n",
       "48506   r1i1p1f1      day          pr         gr   \n",
       "206821  r1i1p1f1      day      tasmax         gr   \n",
       "219098  r1i1p1f1      day      tasmax         gn   \n",
       "219099  r1i1p1f1      day      tasmin         gn   \n",
       "219130  r1i1p1f1      day         hur         gn   \n",
       "219088  r1i1p1f1      day          pr         gn   \n",
       "204547  r1i1p1f1      day      tasmin         gn   \n",
       "204583  r1i1p1f1      day          pr         gn   \n",
       "204972  r1i1p1f1      day         hur         gn   \n",
       "204548  r1i1p1f1      day      tasmax         gn   \n",
       "\n",
       "                                                   zstore  dcpp_init_year  \\\n",
       "203687  gs://cmip6/CMIP6/ScenarioMIP/AWI/AWI-CM-1-1-MR...             NaN   \n",
       "203680  gs://cmip6/CMIP6/ScenarioMIP/AWI/AWI-CM-1-1-MR...             NaN   \n",
       "203625  gs://cmip6/CMIP6/ScenarioMIP/AWI/AWI-CM-1-1-MR...             NaN   \n",
       "203618  gs://cmip6/CMIP6/ScenarioMIP/AWI/AWI-CM-1-1-MR...             NaN   \n",
       "110222  gs://cmip6/CMIP6/ScenarioMIP/CCCma/CanESM5/ssp...             NaN   \n",
       "110210  gs://cmip6/CMIP6/ScenarioMIP/CCCma/CanESM5/ssp...             NaN   \n",
       "110221  gs://cmip6/CMIP6/ScenarioMIP/CCCma/CanESM5/ssp...             NaN   \n",
       "110311  gs://cmip6/CMIP6/ScenarioMIP/CCCma/CanESM5/ssp...             NaN   \n",
       "425694  gs://cmip6/CMIP6/ScenarioMIP/EC-Earth-Consorti...             NaN   \n",
       "425877  gs://cmip6/CMIP6/ScenarioMIP/EC-Earth-Consorti...             NaN   \n",
       "425687  gs://cmip6/CMIP6/ScenarioMIP/EC-Earth-Consorti...             NaN   \n",
       "255053  gs://cmip6/CMIP6/ScenarioMIP/CAS/FGOALS-g3/ssp...             NaN   \n",
       "255060  gs://cmip6/CMIP6/ScenarioMIP/CAS/FGOALS-g3/ssp...             NaN   \n",
       "255056  gs://cmip6/CMIP6/ScenarioMIP/CAS/FGOALS-g3/ssp...             NaN   \n",
       "209150  gs://cmip6/CMIP6/ScenarioMIP/INM/INM-CM5-0/ssp...             NaN   \n",
       "209158  gs://cmip6/CMIP6/ScenarioMIP/INM/INM-CM5-0/ssp...             NaN   \n",
       "209169  gs://cmip6/CMIP6/ScenarioMIP/INM/INM-CM5-0/ssp...             NaN   \n",
       "209180  gs://cmip6/CMIP6/ScenarioMIP/INM/INM-CM5-0/ssp...             NaN   \n",
       "48510   gs://cmip6/CMIP6/ScenarioMIP/IPSL/IPSL-CM6A-LR...             NaN   \n",
       "48355   gs://cmip6/CMIP6/ScenarioMIP/IPSL/IPSL-CM6A-LR...             NaN   \n",
       "48506   gs://cmip6/CMIP6/ScenarioMIP/IPSL/IPSL-CM6A-LR...             NaN   \n",
       "206821  gs://cmip6/CMIP6/ScenarioMIP/IPSL/IPSL-CM6A-LR...             NaN   \n",
       "219098  gs://cmip6/CMIP6/ScenarioMIP/MPI-M/MPI-ESM1-2-...             NaN   \n",
       "219099  gs://cmip6/CMIP6/ScenarioMIP/MPI-M/MPI-ESM1-2-...             NaN   \n",
       "219130  gs://cmip6/CMIP6/ScenarioMIP/MPI-M/MPI-ESM1-2-...             NaN   \n",
       "219088  gs://cmip6/CMIP6/ScenarioMIP/MPI-M/MPI-ESM1-2-...             NaN   \n",
       "204547  gs://cmip6/CMIP6/ScenarioMIP/MRI/MRI-ESM2-0/ss...             NaN   \n",
       "204583  gs://cmip6/CMIP6/ScenarioMIP/MRI/MRI-ESM2-0/ss...             NaN   \n",
       "204972  gs://cmip6/CMIP6/ScenarioMIP/MRI/MRI-ESM2-0/ss...             NaN   \n",
       "204548  gs://cmip6/CMIP6/ScenarioMIP/MRI/MRI-ESM2-0/ss...             NaN   \n",
       "\n",
       "         version  \n",
       "203687  20190529  \n",
       "203680  20190529  \n",
       "203625  20190529  \n",
       "203618  20190529  \n",
       "110222  20190429  \n",
       "110210  20190429  \n",
       "110221  20190429  \n",
       "110311  20190429  \n",
       "425694  20200310  \n",
       "425877  20200310  \n",
       "425687  20200310  \n",
       "255053  20190818  \n",
       "255060  20190818  \n",
       "255056  20190818  \n",
       "209150  20190619  \n",
       "209158  20190619  \n",
       "209169  20190619  \n",
       "209180  20190619  \n",
       "48510   20190119  \n",
       "48355   20190119  \n",
       "48506   20190119  \n",
       "206821  20190614  \n",
       "219098  20190710  \n",
       "219099  20190710  \n",
       "219130  20190710  \n",
       "219088  20190710  \n",
       "204547  20190603  \n",
       "204583  20190603  \n",
       "204972  20190603  \n",
       "204548  20190603  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# refine the list to include only the chosen models\n",
    "models = ['AWI-CM-1-1-MR', 'CESM2', 'CanESM5', 'EC-Earth3', \n",
    "          'FGOALS-g3','INM-CM5-0', 'IPSL-CM6A-LR', 'MPI-ESM1-2-LR', 'MRI-ESM2-0']\n",
    "df_search_mm = df_search_mm.query(f\"source_id == {models}\")\n",
    "df_search_mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ce756b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for pre-processing data\n",
    "def get_and_process_data(catalog_df, model, scenario, gcs, lat, lon, years):\n",
    "    # get the ztore url for this model and scenario\n",
    "    df_scen = df_catalog.query(f\"source_id == '{model}' & experiment_id == '{scenario}'\")\n",
    "    zstore_url = df_scen.zstore.values[0]\n",
    "    \n",
    "    # get the GCS mapper from the url\n",
    "    mapper = gcs.get_mapper(zstore_url)\n",
    "    \n",
    "    # open the file with xarray\n",
    "    ds = xr.open_zarr(mapper, consolidated = True)\n",
    "    \n",
    "    # get the tas data, select the time period, and interp to the desired location\n",
    "    tas_loc = ds.tas.sel(time = ds.time.dt.year.isin(years)).interp(lat = lat, lon = lon)\n",
    "    \n",
    "    # drop 'height' coordinate, which is always 2m but isn't present on all datasets\n",
    "    if 'height' in tas_loc.coords.keys():\n",
    "        tas_loc = tas_loc.reset_coords('height', drop = True)\n",
    "        \n",
    "    # some datasets put the date at 12:00 whereas some put it at 00:00. To make all\n",
    "    # of them consistent, simply change the time coordinate to the date only\n",
    "    tas_loc = tas_loc.assign_coords(time = tas_loc.time.dt.floor('D'))\n",
    "    # convert from Kelvin to Celsius and return\n",
    "    \n",
    "    tas_loc = tas_loc - 273.15\n",
    "    return tas_loc.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5919c58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for downloading the data\n",
    "def download_data_multimodel(catalog_df, gcs, models, scenario,\n",
    "                             stn_lat, stn_lon,\n",
    "                             years_hist, years_future):\n",
    "\n",
    "    ds_list_hist = []\n",
    "    ds_list_future = []\n",
    "    for model in models:\n",
    "        print(f\"========================{model}=============================\")\n",
    "        print('historical')\n",
    "        tas_model_hist = get_and_process_data(catalog_df, model, 'historical', \n",
    "                                              gcs, stn_lat, stn_lon, years_hist)\n",
    "        ds_list_hist.append(tas_model_hist)\n",
    "    \n",
    "        # get the future simulation data for this model and scenario\n",
    "        print(scenario)\n",
    "        tas_model_future = get_and_process_data(catalog_df, model, scenario, \n",
    "                                                gcs, stn_lat, stn_lon, years_future)\n",
    "        ds_list_future.append(tas_model_future)\n",
    "\n",
    "    print('finished acquiring model data')\n",
    "    \n",
    "    # concatenate the ds_lists together\n",
    "    ds_ens_hist_raw = xce.create_ensemble(ds_list_hist,                             \n",
    "                                          realizations = models,\n",
    "                                          calendar = 'noleap') # common calendar to place all models onto\n",
    "\n",
    "    ds_ens_future_raw = xce.create_ensemble(ds_list_future, \n",
    "                          # names of each model, which is represented by a dimension called 'realization'\n",
    "                                           realizations = models,\n",
    "                                           calendar = 'noleap')\n",
    "\n",
    "    \n",
    "    # return\n",
    "    return ds_ens_hist_raw, ds_ens_future_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de390baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================AWI-CM-1-1-MR=============================\n",
      "historical\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'sparse' has no attribute 'SparseArray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# use the function to download the data, this may take a few minutes to run\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(fout_hist)) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(fout_future)):\n\u001b[1;32m---> 10\u001b[0m     ds_ens_hist_raw, ds_ens_ssp2_raw \u001b[38;5;241m=\u001b[39m download_data_multimodel(df_search_mm, gcs, models, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mssp245\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m                                                                   stn_lat, stn_lon, years_hist, years_future)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# write the data to output files \u001b[39;00m\n\u001b[0;32m     14\u001b[0m     ds_ens_hist_raw\u001b[38;5;241m.\u001b[39mto_netcdf(fout_hist)\n",
      "Cell \u001b[1;32mIn[39], line 11\u001b[0m, in \u001b[0;36mdownload_data_multimodel\u001b[1;34m(catalog_df, gcs, models, scenario, stn_lat, stn_lon, years_hist, years_future)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m========================\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=============================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistorical\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m tas_model_hist \u001b[38;5;241m=\u001b[39m get_and_process_data(catalog_df, model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistorical\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     12\u001b[0m                                       gcs, stn_lat, stn_lon, years_hist)\n\u001b[0;32m     13\u001b[0m ds_list_hist\u001b[38;5;241m.\u001b[39mappend(tas_model_hist)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# get the future simulation data for this model and scenario\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[38], line 11\u001b[0m, in \u001b[0;36mget_and_process_data\u001b[1;34m(catalog_df, model, scenario, gcs, lat, lon, years)\u001b[0m\n\u001b[0;32m      8\u001b[0m mapper \u001b[38;5;241m=\u001b[39m gcs\u001b[38;5;241m.\u001b[39mget_mapper(zstore_url)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# open the file with xarray\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m ds \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_zarr(mapper, consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# get the tas data, select the time period, and interp to the desired location\u001b[39;00m\n\u001b[0;32m     14\u001b[0m tas_loc \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mtas\u001b[38;5;241m.\u001b[39msel(time \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mtime\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39myear\u001b[38;5;241m.\u001b[39misin(years))\u001b[38;5;241m.\u001b[39minterp(lat \u001b[38;5;241m=\u001b[39m lat, lon \u001b[38;5;241m=\u001b[39m lon)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xarray\\backends\\zarr.py:844\u001b[0m, in \u001b[0;36mopen_zarr\u001b[1;34m(store, group, synchronizer, chunks, decode_cf, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, consolidated, overwrite_encoded_chunks, chunk_store, storage_options, decode_timedelta, use_cftime, zarr_version, chunked_array_type, from_array_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    791\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_zarr\u001b[39m(\n\u001b[0;32m    792\u001b[0m     store,\n\u001b[0;32m    793\u001b[0m     group\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    811\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    812\u001b[0m ):\n\u001b[0;32m    813\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load and decode a dataset from a Zarr store.\u001b[39;00m\n\u001b[0;32m    814\u001b[0m \n\u001b[0;32m    815\u001b[0m \u001b[38;5;124;03m    The `store` object should be a valid store for a Zarr group. `store`\u001b[39;00m\n\u001b[0;32m    816\u001b[0m \u001b[38;5;124;03m    variables must contain dimension metadata encoded in the\u001b[39;00m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;124;03m    `_ARRAY_DIMENSIONS` attribute or must have NCZarr format.\u001b[39;00m\n\u001b[0;32m    818\u001b[0m \n\u001b[0;32m    819\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m    820\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[0;32m    821\u001b[0m \u001b[38;5;124;03m    store : MutableMapping or str\u001b[39;00m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;124;03m        A MutableMapping where a Zarr Group has been stored or a path to a\u001b[39;00m\n\u001b[0;32m    823\u001b[0m \u001b[38;5;124;03m        directory in file system where a Zarr DirectoryStore has been stored.\u001b[39;00m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;124;03m    synchronizer : object, optional\u001b[39;00m\n\u001b[0;32m    825\u001b[0m \u001b[38;5;124;03m        Array synchronizer provided to zarr\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;124;03m    group : str, optional\u001b[39;00m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;124;03m        Group path. (a.k.a. `path` in zarr terminology.)\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;124;03m    chunks : int or dict or tuple or {None, 'auto'}, optional\u001b[39;00m\n\u001b[0;32m    829\u001b[0m \u001b[38;5;124;03m        Chunk sizes along each dimension, e.g., ``5`` or\u001b[39;00m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;124;03m        ``{'x': 5, 'y': 5}``. If `chunks='auto'`, dask chunks are created\u001b[39;00m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;124;03m        based on the variable's zarr chunks. If `chunks=None`, zarr array\u001b[39;00m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;124;03m        data will lazily convert to numpy arrays upon access. This accepts\u001b[39;00m\n\u001b[0;32m    833\u001b[0m \u001b[38;5;124;03m        all the chunk specifications as Dask does.\u001b[39;00m\n\u001b[0;32m    834\u001b[0m \u001b[38;5;124;03m    overwrite_encoded_chunks : bool, optional\u001b[39;00m\n\u001b[0;32m    835\u001b[0m \u001b[38;5;124;03m        Whether to drop the zarr chunks encoded for each variable when a\u001b[39;00m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;124;03m        dataset is loaded with specified chunk sizes (default: False)\u001b[39;00m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;124;03m    decode_cf : bool, optional\u001b[39;00m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;124;03m        Whether to decode these variables, assuming they were saved according\u001b[39;00m\n\u001b[0;32m    839\u001b[0m \u001b[38;5;124;03m        to CF conventions.\u001b[39;00m\n\u001b[0;32m    840\u001b[0m \u001b[38;5;124;03m    mask_and_scale : bool, optional\u001b[39;00m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;124;03m        If True, replace array values equal to `_FillValue` with NA and scale\u001b[39;00m\n\u001b[0;32m    842\u001b[0m \u001b[38;5;124;03m        values according to the formula `original_values * scale_factor +\u001b[39;00m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;124;03m        add_offset`, where `_FillValue`, `scale_factor` and `add_offset` are\u001b[39;00m\n\u001b[1;32m--> 844\u001b[0m \u001b[38;5;124;03m        taken from variable attributes (if they exist).  If the `_FillValue` or\u001b[39;00m\n\u001b[0;32m    845\u001b[0m \u001b[38;5;124;03m        `missing_value` attribute contains multiple values a warning will be\u001b[39;00m\n\u001b[0;32m    846\u001b[0m \u001b[38;5;124;03m        issued and all array values matching one of the multiple values will\u001b[39;00m\n\u001b[0;32m    847\u001b[0m \u001b[38;5;124;03m        be replaced by NA.\u001b[39;00m\n\u001b[0;32m    848\u001b[0m \u001b[38;5;124;03m    decode_times : bool, optional\u001b[39;00m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;124;03m        If True, decode times encoded in the standard NetCDF datetime format\u001b[39;00m\n\u001b[0;32m    850\u001b[0m \u001b[38;5;124;03m        into datetime objects. Otherwise, leave them encoded as numbers.\u001b[39;00m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;124;03m    concat_characters : bool, optional\u001b[39;00m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;124;03m        If True, concatenate along the last dimension of character arrays to\u001b[39;00m\n\u001b[0;32m    853\u001b[0m \u001b[38;5;124;03m        form string arrays. Dimensions will only be concatenated over (and\u001b[39;00m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;124;03m        removed) if they have no corresponding variable and if they are only\u001b[39;00m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;124;03m        used as the last dimension of character arrays.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;124;03m    decode_coords : bool, optional\u001b[39;00m\n\u001b[0;32m    857\u001b[0m \u001b[38;5;124;03m        If True, decode the 'coordinates' attribute to identify coordinates in\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;124;03m        the resulting dataset.\u001b[39;00m\n\u001b[0;32m    859\u001b[0m \u001b[38;5;124;03m    drop_variables : str or iterable, optional\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;124;03m        A variable or list of variables to exclude from being parsed from the\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;124;03m        dataset. This may be useful to drop variables with problems or\u001b[39;00m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;124;03m        inconsistent values.\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;124;03m    consolidated : bool, optional\u001b[39;00m\n\u001b[0;32m    864\u001b[0m \u001b[38;5;124;03m        Whether to open the store using zarr's consolidated metadata\u001b[39;00m\n\u001b[0;32m    865\u001b[0m \u001b[38;5;124;03m        capability. Only works for stores that have already been consolidated.\u001b[39;00m\n\u001b[0;32m    866\u001b[0m \u001b[38;5;124;03m        By default (`consolidate=None`), attempts to read consolidated metadata,\u001b[39;00m\n\u001b[0;32m    867\u001b[0m \u001b[38;5;124;03m        falling back to read non-consolidated metadata if that fails.\u001b[39;00m\n\u001b[0;32m    868\u001b[0m \n\u001b[0;32m    869\u001b[0m \u001b[38;5;124;03m        When the experimental ``zarr_version=3``, ``consolidated`` must be\u001b[39;00m\n\u001b[0;32m    870\u001b[0m \u001b[38;5;124;03m        either be ``None`` or ``False``.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;124;03m    chunk_store : MutableMapping, optional\u001b[39;00m\n\u001b[0;32m    872\u001b[0m \u001b[38;5;124;03m        A separate Zarr store only for chunk data.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m \u001b[38;5;124;03m    storage_options : dict, optional\u001b[39;00m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;124;03m        Any additional parameters for the storage backend (ignored for local\u001b[39;00m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;124;03m        paths).\u001b[39;00m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;124;03m    decode_timedelta : bool, optional\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;124;03m        If True, decode variables and coordinates with time units in\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;124;03m        {'days', 'hours', 'minutes', 'seconds', 'milliseconds', 'microseconds'}\u001b[39;00m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;124;03m        into timedelta objects. If False, leave them encoded as numbers.\u001b[39;00m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;124;03m        If None (default), assume the same value of decode_time.\u001b[39;00m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;124;03m    use_cftime : bool, optional\u001b[39;00m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;124;03m        Only relevant if encoded dates come from a standard calendar\u001b[39;00m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;124;03m        (e.g. \"gregorian\", \"proleptic_gregorian\", \"standard\", or not\u001b[39;00m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;124;03m        specified).  If None (default), attempt to decode times to\u001b[39;00m\n\u001b[0;32m    885\u001b[0m \u001b[38;5;124;03m        ``np.datetime64[ns]`` objects; if this is not possible, decode times to\u001b[39;00m\n\u001b[0;32m    886\u001b[0m \u001b[38;5;124;03m        ``cftime.datetime`` objects. If True, always decode times to\u001b[39;00m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;124;03m        ``cftime.datetime`` objects, regardless of whether or not they can be\u001b[39;00m\n\u001b[0;32m    888\u001b[0m \u001b[38;5;124;03m        represented using ``np.datetime64[ns]`` objects.  If False, always\u001b[39;00m\n\u001b[0;32m    889\u001b[0m \u001b[38;5;124;03m        decode times to ``np.datetime64[ns]`` objects; if this is not possible\u001b[39;00m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;124;03m        raise an error.\u001b[39;00m\n\u001b[0;32m    891\u001b[0m \u001b[38;5;124;03m    zarr_version : int or None, optional\u001b[39;00m\n\u001b[0;32m    892\u001b[0m \u001b[38;5;124;03m        The desired zarr spec version to target (currently 2 or 3). The default\u001b[39;00m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;124;03m        of None will attempt to determine the zarr version from ``store`` when\u001b[39;00m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;124;03m        possible, otherwise defaulting to 2.\u001b[39;00m\n\u001b[0;32m    895\u001b[0m \u001b[38;5;124;03m    chunked_array_type: str, optional\u001b[39;00m\n\u001b[0;32m    896\u001b[0m \u001b[38;5;124;03m        Which chunked array type to coerce this datasets' arrays to.\u001b[39;00m\n\u001b[0;32m    897\u001b[0m \u001b[38;5;124;03m        Defaults to 'dask' if installed, else whatever is registered via the `ChunkManagerEntryPoint` system.\u001b[39;00m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;124;03m        Experimental API that should not be relied upon.\u001b[39;00m\n\u001b[0;32m    899\u001b[0m \u001b[38;5;124;03m    from_array_kwargs: dict, optional\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;124;03m        Additional keyword arguments passed on to the `ChunkManagerEntrypoint.from_array` method used to create\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;124;03m        chunked arrays, via whichever chunk manager is specified through the `chunked_array_type` kwarg.\u001b[39;00m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;124;03m        Defaults to {'manager': 'dask'}, meaning additional kwargs will be passed eventually to\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;124;03m        :py:func:`dask.array.from_array`. Experimental API that should not be relied upon.\u001b[39;00m\n\u001b[0;32m    904\u001b[0m \n\u001b[0;32m    905\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[0;32m    907\u001b[0m \u001b[38;5;124;03m    dataset : Dataset\u001b[39;00m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;124;03m        The newly created dataset.\u001b[39;00m\n\u001b[0;32m    909\u001b[0m \n\u001b[0;32m    910\u001b[0m \u001b[38;5;124;03m    See Also\u001b[39;00m\n\u001b[0;32m    911\u001b[0m \u001b[38;5;124;03m    --------\u001b[39;00m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;124;03m    open_dataset\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;124;03m    open_mfdataset\u001b[39;00m\n\u001b[0;32m    914\u001b[0m \n\u001b[0;32m    915\u001b[0m \u001b[38;5;124;03m    References\u001b[39;00m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[0;32m    917\u001b[0m \u001b[38;5;124;03m    http://zarr.readthedocs.io/\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m open_dataset\n\u001b[0;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m from_array_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xarray\\core\\parallelcompat.py:75\u001b[0m, in \u001b[0;36mguess_chunkmanager\u001b[1;34m(manager)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xarray\\core\\parallelcompat.py:45\u001b[0m, in \u001b[0;36mlist_chunkmanagers\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xarray\\core\\parallelcompat.py:57\u001b[0m, in \u001b[0;36mload_chunkmanagers\u001b[1;34m(entrypoints)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xarray\\core\\parallelcompat.py:58\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xarray\\namedarray\\daskmanager.py:37\u001b[0m, in \u001b[0;36mDaskManager.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;66;03m# TODO can we replace this with a class attribute instead?\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Array\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray_cls \u001b[38;5;241m=\u001b[39m Array\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dask\\array\\__init__.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backends, fft, lib, linalg, ma, overlap, random\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblockwise\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m atop, blockwise\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchunk_types\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_chunk_type\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dask\\array\\backends.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m chunk\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Array\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdispatch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     concatenate_lookup,\n\u001b[0;32m     11\u001b[0m     divide_lookup,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m     to_numpy_dispatch,\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy_compat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m divide \u001b[38;5;28;01mas\u001b[39;00m np_divide\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dask\\array\\core.py:37\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m chunk\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchunk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m getitem\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchunk_types\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_valid_array_chunk, is_valid_chunk_type\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Keep einsum_lookup and tensordot_lookup here for backwards compatibility\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdispatch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     concatenate_lookup,\n\u001b[0;32m     42\u001b[0m     einsum_lookup,\n\u001b[0;32m     43\u001b[0m     tensordot_lookup,\n\u001b[0;32m     44\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\dask\\array\\chunk_types.py:126\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msparse\u001b[39;00m\n\u001b[1;32m--> 126\u001b[0m     register_chunk_type(sparse\u001b[38;5;241m.\u001b[39mSparseArray)\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'sparse' has no attribute 'SparseArray'"
     ]
    }
   ],
   "source": [
    "# authenticate access to Google Cloud\n",
    "gcs = gcsfs.GCSFileSystem(token='anon')\n",
    "\n",
    "# file names to save the downloaded data, to save time later when re-running this notebook\n",
    "fout_hist = 'data_files/tasmax.cmip6.daily.historical.r4i1p1f1.1980-2010.EA.nc'\n",
    "fout_future = 'data_files/tasmax.cmip6.daily.ssp3.r4i1p1f1.2030-2060.EA.nc'\n",
    "\n",
    "# use the function to download the data, this may take a few minutes to run\n",
    "if (not os.path.exists(fout_hist)) or (not os.path.exists(fout_future)):\n",
    "    ds_ens_hist_raw, ds_ens_ssp2_raw = download_data_multimodel(df_search_mm, gcs, models, \"ssp245\",\n",
    "                                                                  stn_lat, stn_lon, years_hist, years_future)\n",
    "\n",
    "    # write the data to output files \n",
    "    ds_ens_hist_raw.to_netcdf(fout_hist)\n",
    "    ds_ens_ssp3_raw.to_netcdf(fout_future)\n",
    "else:\n",
    "    # open the files that already exist\n",
    "    ds_ens_hist_raw = xr.open_dataset(fout_hist)\n",
    "    ds_ens_ssp3_raw = xr.open_dataset(fout_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "788919c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_scen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_scen\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_scen' is not defined"
     ]
    }
   ],
   "source": [
    "df_scen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc6847a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
